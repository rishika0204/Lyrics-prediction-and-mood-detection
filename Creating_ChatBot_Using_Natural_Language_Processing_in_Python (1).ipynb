{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R06i-jGuTPG_",
        "outputId": "356957e4-4d91-4693-d87b-2b5f6058a544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as num\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tensorF\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnjmqXftU3aX"
      },
      "outputs": [],
      "source": [
        "ourData = {\"intents\": [\n",
        "\n",
        "             {\"tag\": \"age\",\n",
        "              \"patterns\": [\"Ukona myaka ngapi?\"],\n",
        "              \"responses\": [\"Mbili tu\"]\n",
        "             },\n",
        "              {\"tag\": \"greeting\",\n",
        "              \"patterns\": [ \"Niaje\", \"Hello\", \"Hey\"],\n",
        "              \"responses\": [\"Poa\", \"Fiti\", \"Niko fine :)\"],\n",
        "             },\n",
        "              {\"tag\": \"goodbye\",\n",
        "              \"patterns\": [ \"bye\", \"later\"],\n",
        "              \"responses\": [\"Bye\", \"take care\"]\n",
        "             },\n",
        "             {\"tag\": \"name\",\n",
        "              \"patterns\": [\"what's your name?\", \"who are you?\"],\n",
        "              \"responses\": [\"I have no name yet\", \"You can give me one and i will apreciate\"]\n",
        "             }\n",
        "\n",
        "]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wouD59W4Thno"
      },
      "outputs": [],
      "source": [
        "lm = WordNetLemmatizer() #for getting words\n",
        "# lists\n",
        "ourClasses = []\n",
        "newWords = []\n",
        "documentX = []\n",
        "documentY = []\n",
        "# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n",
        "for intent in ourData[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        ourTokens = nltk.word_tokenize(pattern)\n",
        "        newWords.extend(ourTokens)\n",
        "        documentX.append(pattern)\n",
        "        documentY.append(intent[\"tag\"])\n",
        "\n",
        "\n",
        "    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n",
        "        ourClasses.append(intent[\"tag\"])\n",
        "\n",
        "newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n",
        "newWords = sorted(set(newWords))# sorting words\n",
        "ourClasses = sorted(set(ourClasses))# sorting classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sIDY0cUVC8w",
        "outputId": "496bc068-d523-4330-a1c5-018cc0e48e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"'s\", 'are', 'bye', 'hello', 'hey', 'later', 'myaka', 'name', 'ngapi', 'niaje', 'ukona', 'what', 'who', 'you', 'your']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(newWords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypz2D9ywVjRs",
        "outputId": "cac00b3d-e957-4e57-e769-baeafe18e370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['age', 'goodbye', 'greeting', 'name']\n"
          ]
        }
      ],
      "source": [
        "print(ourClasses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SShwtVFtaBL7"
      },
      "outputs": [],
      "source": [
        "trainingData = [] # training list array\n",
        "outEmpty = [0] * len(ourClasses)\n",
        "# BOW model\n",
        "for idx, doc in enumerate(documentX):\n",
        "    bagOfwords = []\n",
        "    text = lm.lemmatize(doc.lower())\n",
        "    for word in newWords:\n",
        "        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n",
        "\n",
        "    outputRow = list(outEmpty)\n",
        "    outputRow[ourClasses.index(documentY[idx])] = 1\n",
        "    trainingData.append([bagOfwords, outputRow])\n",
        "\n",
        "random.shuffle(trainingData)\n",
        "trainingData = num.array(trainingData, dtype=object)# coverting our data into an array afterv shuffling\n",
        "\n",
        "x = num.array(list(trainingData[:, 0]))# first trainig phase\n",
        "y = num.array(list(trainingData[:, 1]))# second training phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "w07_i51kaHPg",
        "outputId": "4b4ccf29-d825-42a4-fc67-6ccecd3342b2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ef25587d9738>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mourNewModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mourNewModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m ourNewModel.compile(loss='categorical_crossentropy',\n\u001b[1;32m     14\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     ):\n\u001b[0;32m--> 104\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;34m\"\"\"Create a new Optimizer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iteration_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_iteration_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_process_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlegacy_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0;34mf\"{k} is deprecated in the new Keras optimizer, please\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;34m\"check the docstring for valid arguments, or use the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam."
          ]
        }
      ],
      "source": [
        "# defining some parameters\n",
        "iShape = (len(x[0]),)\n",
        "oShape = len(y[0])\n",
        "\n",
        "# the deep learning model\n",
        "ourNewModel = Sequential()\n",
        "ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n",
        "ourNewModel.add(Dropout(0.5))\n",
        "ourNewModel.add(Dense(64, activation=\"relu\"))\n",
        "ourNewModel.add(Dropout(0.3))\n",
        "ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n",
        "md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
        "ourNewModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=md,\n",
        "              metrics=[\"accuracy\"])\n",
        "print(ourNewModel.summary())\n",
        "ourNewModel.fit(x, y, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLfDyof6aR1U"
      },
      "outputs": [],
      "source": [
        "def ourText(text):\n",
        "  newtkns = nltk.word_tokenize(text)\n",
        "  newtkns = [lm.lemmatize(word) for word in newtkns]\n",
        "  return newtkns\n",
        "\n",
        "def wordBag(text, vocab):\n",
        "  newtkns = ourText(text)\n",
        "  bagOwords = [0] * len(vocab)\n",
        "  for w in newtkns:\n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w:\n",
        "        bagOwords[idx] = 1\n",
        "  return num.array(bagOwords)\n",
        "\n",
        "def pred_class(text, vocab, labels):\n",
        "  bagOwords = wordBag(text, vocab)\n",
        "  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n",
        "  newThresh = 0.2\n",
        "  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n",
        "\n",
        "  yp.sort(key=lambda x: x[1], reverse=True)\n",
        "  newList = []\n",
        "  for r in yp:\n",
        "    newList.append(labels[r[0]])\n",
        "  return newList\n",
        "\n",
        "def getRes(firstlist, fJson):\n",
        "  tag = firstlist[0]\n",
        "  listOfIntents = fJson[\"intents\"]\n",
        "  for i in listOfIntents:\n",
        "    if i[\"tag\"] == tag:\n",
        "      ourResult = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  return ourResult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS1lJZjLa44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "2d55689b-6bd4-4a11-e9f0-df47b228c341"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-548e35d82d70>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnewMessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mourClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mourResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mourData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mourResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    newMessage = input(\"\")\n",
        "    intents = pred_class(newMessage, newWords, ourClasses)\n",
        "    ourResult = getRes(intents, ourData)\n",
        "    print(ourResult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mubyXIWka9-H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "w07_i51kaHPg"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}